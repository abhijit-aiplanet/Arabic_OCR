# ğŸ“ Project Structure

Complete overview of the AIN OCR project structure after refactoring.

## Directory Layout

```
Dots-OCR/
â”‚
â”œâ”€â”€ ğŸ“ backend/                      # FastAPI Backend Service
â”‚   â”œâ”€â”€ main.py                      # Main FastAPI application
â”‚   â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚   â”œâ”€â”€ vercel.json                  # Vercel deployment configuration
â”‚   â”œâ”€â”€ env.example                  # Example environment variables
â”‚   â””â”€â”€ README.md                    # Backend documentation
â”‚
â”œâ”€â”€ ğŸ“ frontend/                     # Next.js Frontend Application
â”‚   â”œâ”€â”€ ğŸ“ src/
â”‚   â”‚   â”œâ”€â”€ ğŸ“ app/                 # Next.js App Router
â”‚   â”‚   â”‚   â”œâ”€â”€ layout.tsx          # Root layout component
â”‚   â”‚   â”‚   â””â”€â”€ page.tsx            # Home page
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ components/          # React Components
â”‚   â”‚   â”‚   â”œâ”€â”€ ImageUploader.tsx   # Image upload component
â”‚   â”‚   â”‚   â”œâ”€â”€ ExtractedText.tsx   # Text display component
â”‚   â”‚   â”‚   â””â”€â”€ AdvancedSettings.tsx # Settings panel
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ lib/                 # Utilities & API
â”‚   â”‚   â”‚   â””â”€â”€ api.ts              # API client functions
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“ styles/              # Global Styles
â”‚   â”‚       â””â”€â”€ globals.css         # Global CSS with Tailwind
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ public/                  # Static Assets
â”‚   â”œâ”€â”€ package.json                # Node.js dependencies
â”‚   â”œâ”€â”€ tsconfig.json               # TypeScript configuration
â”‚   â”œâ”€â”€ next.config.js              # Next.js configuration
â”‚   â”œâ”€â”€ tailwind.config.js          # Tailwind CSS configuration
â”‚   â”œâ”€â”€ postcss.config.js           # PostCSS configuration
â”‚   â”œâ”€â”€ env.local.example           # Example environment variables
â”‚   â”œâ”€â”€ .gitignore                  # Git ignore rules
â”‚   â””â”€â”€ README.md                   # Frontend documentation
â”‚
â”œâ”€â”€ ğŸ“ model-service/               # RunPod Model Service
â”‚   â”œâ”€â”€ handler.py                  # RunPod serverless handler
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile                  # Docker configuration
â”‚   â”œâ”€â”€ test_handler.py             # Local testing script
â”‚   â””â”€â”€ README.md                   # Model service documentation
â”‚
â”œâ”€â”€ ğŸ“ image/                       # Example Images (from original)
â”‚   â””â”€â”€ ğŸ“ app/
â”‚       â”œâ”€â”€ 1762329983969.png
â”‚       â”œâ”€â”€ 1762330009302.png
â”‚       â””â”€â”€ 1762330020168.png
â”‚
â”œâ”€â”€ ğŸ“„ DEPLOYMENT_GUIDE.md          # Complete deployment guide
â”œâ”€â”€ ğŸ“„ SETUP_INSTRUCTIONS.txt       # Quick setup checklist
â”œâ”€â”€ ğŸ“„ PROJECT_STRUCTURE.md         # This file
â”œâ”€â”€ ğŸ“„ README.md                    # Main project README
â”‚
â””â”€â”€ ğŸ“ (Original files - can be archived)
    â”œâ”€â”€ ain_app.py                  # Original Gradio app
    â”œâ”€â”€ app.py                      # Original app
    â”œâ”€â”€ deepseek_app.py            # Alternative implementation
    â”œâ”€â”€ arabic_corrector.py        # Arabic correction module
    â””â”€â”€ requirements.txt            # Original requirements
```

## Components Description

### Backend (FastAPI)

**Purpose**: RESTful API service that acts as middleware between frontend and model service.

**Key Files**:
- `main.py`: Core API with endpoints for OCR processing, health checks, and configuration
- `requirements.txt`: FastAPI, httpx, Pillow, and other dependencies
- `vercel.json`: Configuration for Vercel serverless deployment
- `env.example`: Template for environment variables

**Key Features**:
- CORS middleware for frontend communication
- Image validation and preprocessing
- Async communication with RunPod model service
- Error handling and timeout management

**API Endpoints**:
- `POST /api/ocr`: Process image and extract text
- `GET /api/prompt`: Get default OCR prompt
- `GET /health`: Health check endpoint
- `GET /`: API information

### Frontend (Next.js + TypeScript)

**Purpose**: Modern, responsive web interface for image upload and text extraction.

**Tech Stack**:
- Next.js 14 (App Router)
- TypeScript
- Tailwind CSS
- React Dropzone
- Axios
- React Hot Toast

**Key Components**:

1. **ImageUploader.tsx**
   - Drag & drop image upload
   - Image preview
   - File type validation

2. **ExtractedText.tsx**
   - Display extracted text
   - Copy to clipboard functionality
   - Character and word count

3. **AdvancedSettings.tsx**
   - Collapsible settings panel
   - Custom prompt input
   - Resolution and token configuration

4. **api.ts**
   - API client functions
   - HTTP request handling
   - Error management

**Key Features**:
- Responsive design (mobile, tablet, desktop)
- Real-time processing status
- Toast notifications
- Arabic text support (RTL)
- Modern gradient UI

### Model Service (RunPod)

**Purpose**: GPU-powered inference service running the MBZUAI/AIN model.

**Key Files**:
- `handler.py`: RunPod serverless handler implementing the model inference
- `Dockerfile`: Container configuration for deployment
- `test_handler.py`: Local testing without deploying
- `requirements.txt`: Model dependencies (transformers, torch, etc.)

**Key Features**:
- Automatic model loading with error recovery
- Base64 image processing
- GPU optimization
- Configurable inference parameters
- Error handling and logging

**Model Details**:
- Model: MBZUAI/AIN (Vision Language Model)
- Size: ~20GB
- VRAM Required: 20-25GB
- Inference Time: 3-5 seconds per image

## Data Flow

```
1. User uploads image in Frontend
   â†“
2. Frontend sends to Backend API (multipart/form-data)
   â†“
3. Backend validates and converts image to base64
   â†“
4. Backend sends request to RunPod Model Service
   â†“
5. Model Service processes image with AIN VLM
   â†“
6. Model Service returns extracted text
   â†“
7. Backend forwards response to Frontend
   â†“
8. Frontend displays extracted text to user
```

## Deployment Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         User's Browser                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend (Vercel Edge Network)        â”‚
â”‚   â€¢ Next.js Static + Server Components  â”‚
â”‚   â€¢ Global CDN Distribution              â”‚
â”‚   â€¢ Auto HTTPS                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ HTTPS API Call
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Backend (Vercel Serverless)           â”‚
â”‚   â€¢ FastAPI on AWS Lambda               â”‚
â”‚   â€¢ Auto-scaling                         â”‚
â”‚   â€¢ 10s request timeout                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ HTTPS API Call
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Model Service (RunPod GPU)            â”‚
â”‚   â€¢ RTX A6000 / A40 GPU                 â”‚
â”‚   â€¢ Serverless or Dedicated Pod         â”‚
â”‚   â€¢ Auto-scaling workers                 â”‚
â”‚   â€¢ Container-based deployment          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Environment Variables

### Backend
```env
RUNPOD_ENDPOINT_URL=https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/runsync
RUNPOD_API_KEY=your_runpod_api_key
FRONTEND_URL=https://your-frontend.vercel.app
PORT=8000
```

### Frontend
```env
NEXT_PUBLIC_API_URL=https://your-backend.vercel.app
```

### Model Service
No environment variables needed - fully configured via API calls.

## Technology Stack

### Backend
- **Framework**: FastAPI (Python)
- **HTTP Client**: httpx (async)
- **Image Processing**: Pillow
- **Server**: Uvicorn
- **Deployment**: Vercel Serverless Functions

### Frontend
- **Framework**: Next.js 14
- **Language**: TypeScript
- **Styling**: Tailwind CSS
- **HTTP Client**: Axios
- **File Upload**: React Dropzone
- **Notifications**: React Hot Toast
- **Icons**: Lucide React
- **Deployment**: Vercel Edge Network

### Model Service
- **Framework**: RunPod Serverless
- **Model**: Qwen2VL (MBZUAI/AIN)
- **ML Libraries**: Transformers, PyTorch
- **Image Processing**: Pillow
- **Container**: Docker
- **Deployment**: RunPod GPU Pods

## Security Features

- âœ… CORS configured for specific origins
- âœ… Environment variables for sensitive data
- âœ… File type validation
- âœ… Size limits on uploads
- âœ… HTTPS everywhere
- âœ… No sensitive data in client code
- âœ… API key authentication for model service

## Performance Optimizations

### Frontend
- Next.js SSR and SSG
- Code splitting
- Image optimization
- CDN delivery
- Lazy loading components

### Backend
- Async request handling
- Connection pooling
- Timeout management
- Error recovery

### Model Service
- GPU acceleration
- Model weight caching
- Efficient tokenization
- Batch processing capability

## Scalability

### Current Capacity
- Frontend: Unlimited (CDN)
- Backend: Auto-scales (Vercel)
- Model: 1-5 workers (configurable)

### For High Traffic
1. Increase RunPod max workers (10-20)
2. Use dedicated GPU pods
3. Add request queue (Redis)
4. Implement caching layer
5. Enable auto-scaling on all services

## Monitoring & Logging

### Available Logs
- **Frontend**: Vercel Dashboard â†’ Logs
- **Backend**: Vercel Dashboard â†’ Logs
- **Model Service**: RunPod Dashboard â†’ Endpoint Logs

### Recommended Monitoring
- Vercel Analytics (built-in)
- RunPod usage dashboard
- Custom error tracking (Sentry)
- Uptime monitoring (UptimeRobot)

## Future Enhancements

Potential improvements:
- [ ] Batch processing support
- [ ] PDF and multi-page document support
- [ ] User authentication and accounts
- [ ] Processing history and saved results
- [ ] Multiple language support in UI
- [ ] Export formats (JSON, CSV, PDF)
- [ ] API rate limiting
- [ ] Webhook notifications
- [ ] Custom model fine-tuning
- [ ] Mobile app (React Native)

## Migration from Original

### Changes from Original Application
- âœ… Separated Gradio UI â†’ Modern Next.js frontend
- âœ… Monolithic app â†’ Microservices architecture
- âœ… Local deployment â†’ Cloud deployment
- âœ… Single service â†’ Three independent services
- âœ… Direct model loading â†’ API-based model service

### Preserved Features
- âœ… AIN VLM model for OCR
- âœ… Custom prompt support
- âœ… Advanced settings
- âœ… Arabic text support
- âœ… Example images

### New Features
- âœ… Modern responsive UI
- âœ… Drag & drop upload
- âœ… Real-time notifications
- âœ… Better error handling
- âœ… Scalable architecture
- âœ… Production-ready deployment

## Getting Started

1. **Read Documentation**
   - `SETUP_INSTRUCTIONS.txt` - Quick start
   - `DEPLOYMENT_GUIDE.md` - Detailed deployment steps
   - Component READMEs - Specific guides

2. **Deploy Services** (in order)
   - Model Service (RunPod)
   - Backend (Vercel/Render)
   - Frontend (Vercel)

3. **Configure & Test**
   - Set environment variables
   - Test each service independently
   - Test full integration

4. **Monitor & Maintain**
   - Check logs regularly
   - Monitor costs
   - Update dependencies

---

For detailed deployment instructions, see `DEPLOYMENT_GUIDE.md`

For quick setup, see `SETUP_INSTRUCTIONS.txt`

