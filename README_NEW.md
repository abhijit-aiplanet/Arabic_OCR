# ğŸ” AIN OCR - Vision Language Model for Text Extraction

<div align="center">

![AIN OCR](https://img.shields.io/badge/AIN-OCR-blue?style=for-the-badge)
![Next.js](https://img.shields.io/badge/Next.js-14-black?style=for-the-badge&logo=next.js)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-009688?style=for-the-badge&logo=fastapi)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0-EE4C2C?style=for-the-badge&logo=pytorch)

Advanced OCR application using the MBZUAI/AIN Vision Language Model for accurate text extraction from images.

[Features](#features) â€¢ [Architecture](#architecture) â€¢ [Quick Start](#quick-start) â€¢ [Deployment](#deployment) â€¢ [Documentation](#documentation)

</div>

---

## ğŸ“– Overview

AIN OCR is a production-ready OCR application that leverages the power of Vision Language Models (VLM) for superior text extraction. Unlike traditional OCR systems, it understands context and can handle handwritten text, complex layouts, and multiple languages with high accuracy.

### Why AIN OCR?

- **ğŸ¯ High Accuracy**: Uses MBZUAI/AIN model, specialized for understanding text in context
- **ğŸŒ Multi-language**: Optimized for Arabic, supports many other languages
- **ğŸš€ Production Ready**: Separated frontend/backend/model architecture for scalability
- **ğŸ’° Cost Effective**: Serverless deployment with pay-per-use model
- **ğŸ¨ Modern UI**: Beautiful, responsive interface built with Next.js and Tailwind CSS
- **ğŸ“± Mobile Friendly**: Works seamlessly on all device sizes

## âœ¨ Features

### Core Features
- âœ… Advanced text extraction using Vision Language Models
- âœ… Support for handwritten and printed text
- âœ… Multi-language support (Arabic, English, and more)
- âœ… Maintains original text structure and formatting
- âœ… Configurable inference parameters
- âœ… Custom prompt support for specific extraction needs

### User Interface
- âœ… Drag & drop image upload
- âœ… Real-time processing status
- âœ… One-click copy to clipboard
- âœ… Character and word count
- âœ… Advanced settings panel
- âœ… Toast notifications
- âœ… Responsive design

### Technical Features
- âœ… RESTful API architecture
- âœ… Async request handling
- âœ… GPU-accelerated inference
- âœ… Auto-scaling capabilities
- âœ… Error handling and recovery
- âœ… Health check endpoints
- âœ… CORS support

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚  â† Next.js 14 on Vercel
â”‚   (TypeScript)  â”‚     â€¢ Modern UI with Tailwind CSS
â”‚   Port: 3000    â”‚     â€¢ Drag & drop upload
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â€¢ Real-time notifications
         â”‚
         â”‚ HTTPS
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Backend       â”‚  â† FastAPI on Vercel/Render
â”‚   (Python)      â”‚     â€¢ RESTful API
â”‚   Port: 8000    â”‚     â€¢ Image validation
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â€¢ Request orchestration
         â”‚
         â”‚ HTTPS
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model Service  â”‚  â† MBZUAI/AIN on RunPod
â”‚  (PyTorch)      â”‚     â€¢ GPU inference (RTX A6000)
â”‚  GPU Required   â”‚     â€¢ Serverless scaling
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â€¢ 3-5s per image
```

### Tech Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Frontend** | Next.js 14, TypeScript, Tailwind CSS | Modern web interface |
| **Backend** | FastAPI, Python, httpx | API orchestration |
| **Model Service** | PyTorch, Transformers, RunPod | GPU inference |
| **Deployment** | Vercel, RunPod | Cloud hosting |

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+ (for frontend)
- Python 3.10+ (for backend)
- RunPod account with GPU credits
- Vercel account (free tier works)

### 1. Clone Repository

```bash
git clone https://github.com/your-username/Dots-OCR.git
cd Dots-OCR
```

### 2. Local Development

#### Backend

```bash
cd backend
pip install -r requirements.txt

# Create .env file
cp env.example .env
# Edit .env with your RunPod credentials

# Run server
python main.py
```

Backend runs on `http://localhost:8000`

#### Frontend

```bash
cd frontend
npm install

# Create .env.local file
cp env.local.example .env.local
# Edit .env.local with backend URL

# Run dev server
npm run dev
```

Frontend runs on `http://localhost:3000`

#### Model Service (Optional - for local testing)

```bash
cd model-service
pip install -r requirements.txt

# Test handler
python test_handler.py
```

### 3. Deploy to Production

Follow the comprehensive deployment guide:

```bash
# Read the deployment guide
cat DEPLOYMENT_GUIDE.md

# Quick checklist
cat SETUP_INSTRUCTIONS.txt
```

**Deployment Order:**
1. ğŸ¯ Deploy Model Service on RunPod (15-20 min)
2. ğŸ”§ Deploy Backend on Vercel (5-10 min)
3. ğŸ¨ Deploy Frontend on Vercel (5 min)
4. âœ… Configure environment variables and test

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| [DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md) | Complete deployment instructions |
| [SETUP_INSTRUCTIONS.txt](SETUP_INSTRUCTIONS.txt) | Quick setup checklist |
| [PROJECT_STRUCTURE.md](PROJECT_STRUCTURE.md) | Project organization details |
| [backend/README.md](backend/README.md) | Backend API documentation |
| [frontend/README.md](frontend/README.md) | Frontend development guide |
| [model-service/README.md](model-service/README.md) | Model service setup |

## ğŸ”§ Configuration

### Backend Environment Variables

```env
RUNPOD_ENDPOINT_URL=https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/runsync
RUNPOD_API_KEY=your_runpod_api_key_here
FRONTEND_URL=https://your-frontend.vercel.app
PORT=8000
```

### Frontend Environment Variables

```env
NEXT_PUBLIC_API_URL=https://your-backend.vercel.app
```

## ğŸ’° Cost Estimation

### Low-Medium Traffic (~1000 images/month)

- **RunPod (Serverless)**: $5-$20/month
  - RTX A6000: ~$0.45/hour when active
  - ~$0.0006-$0.001 per image
  - Only pay for actual compute time
  
- **Vercel (Frontend + Backend)**: $0-$20/month
  - Free tier: 100 GB-hours serverless execution
  - Usually sufficient for small-medium projects
  
- **Total**: ~$5-$40/month

### High Traffic

- Increase RunPod max workers (5-10)
- Vercel Pro plan: $20/month
- Consider dedicated GPU pods for consistency
- Estimated: $50-$200/month

## ğŸ“Š Performance

- **Frontend Load Time**: < 1 second (CDN cached)
- **API Response Time**: 3-5 seconds (inference time)
- **Model Inference**: 3-5 seconds per image
- **Throughput**: 10-20 images/minute (serverless)
- **Scalability**: Auto-scales with demand

## ğŸ–¼ï¸ Supported Image Formats

- PNG
- JPEG/JPG
- GIF
- WebP
- BMP

**Recommended**: PNG or JPEG, RGB mode, 300+ DPI for best results

## ğŸŒ API Endpoints

### POST `/api/ocr`
Process an image and extract text.

**Request:**
```bash
curl -X POST https://your-backend.vercel.app/api/ocr \
  -F "file=@image.png" \
  -F "max_new_tokens=2048" \
  -F "min_pixels=200704" \
  -F "max_pixels=1003520"
```

**Response:**
```json
{
  "extracted_text": "Text content from image...",
  "status": "success",
  "error": null
}
```

### GET `/health`
Check API health status.

**Response:**
```json
{
  "status": "healthy",
  "model_service": "configured"
}
```

### GET `/api/prompt`
Get the default OCR prompt.

## ğŸ” Security

- âœ… HTTPS everywhere
- âœ… Environment variables for secrets
- âœ… CORS configured
- âœ… File type validation
- âœ… Size limits on uploads
- âœ… API key authentication
- âœ… No sensitive data in client code

## ğŸ§ª Testing

### Backend Tests
```bash
cd backend
# Start server
python main.py

# Test health endpoint
curl http://localhost:8000/health
```

### Frontend Tests
```bash
cd frontend
npm run dev
# Open http://localhost:3000 and test UI
```

### Model Service Tests
```bash
cd model-service
python test_handler.py
```

## ğŸ› Troubleshooting

### Common Issues

**CORS Errors**
- Ensure `FRONTEND_URL` in backend matches actual frontend URL exactly
- Redeploy backend after changing environment variables

**Timeout Errors**
- Increase RunPod max workers
- Check model service logs in RunPod dashboard
- Verify GPU has sufficient VRAM (24GB+)

**Out of Memory**
- Use GPU with more VRAM (A40 or A6000)
- Reduce `max_pixels` parameter
- Reduce `max_new_tokens` parameter

**Model Not Loading**
- Check container disk size (needs 50GB+)
- Verify RunPod endpoint is active
- Check RunPod logs for errors

## ğŸ“ˆ Scaling Guide

### For Increased Traffic

1. **Increase RunPod Workers**: 1 â†’ 5-10 workers
2. **Upgrade Vercel**: Free â†’ Pro plan ($20/month)
3. **Add Caching**: Implement Redis for response caching
4. **Use Dedicated Pods**: Switch from serverless to dedicated for consistency
5. **Load Balancing**: Multiple RunPod endpoints with round-robin

### Monitoring

- Use Vercel Analytics (built-in)
- Monitor RunPod usage in dashboard
- Set up Sentry for error tracking
- Add UptimeRobot for uptime monitoring

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **MBZUAI** for the AIN Vision Language Model
- **Qwen2-VL** for the base architecture
- **RunPod** for GPU infrastructure
- **Vercel** for serverless deployment platform

## ğŸ“ Support

- ğŸ“§ Email: your-email@example.com
- ğŸ› Issues: [GitHub Issues](https://github.com/your-username/Dots-OCR/issues)
- ğŸ“– Docs: See [Documentation](#documentation) section

## ğŸ—ºï¸ Roadmap

- [ ] Batch processing support
- [ ] PDF and multi-page document support
- [ ] User authentication and accounts
- [ ] Processing history
- [ ] Multiple export formats (JSON, CSV, PDF)
- [ ] Webhook notifications
- [ ] Mobile app (React Native)
- [ ] Custom model fine-tuning interface

---

<div align="center">

**Made with â¤ï¸ using Vision Language Models**

[Report Bug](https://github.com/your-username/Dots-OCR/issues) â€¢ [Request Feature](https://github.com/your-username/Dots-OCR/issues)

</div>

